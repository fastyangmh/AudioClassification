#  parameters configuration
mode: train
root: data/
predefined_dataset: SPEECHCOMMANDS
classes:
  [
    "backward",
    "bed",
    "bird",
    "cat",
    "dog",
    "down",
    "eight",
    "five",
    "follow",
    "forward",
    "four",
    "go",
    "happy",
    "house",
    "learn",
    "left",
    "marvin",
    "nine",
    "no",
    "off",
    "on",
    "one",
    "right",
    "seven",
    "sheila",
    "six",
    "stop",
    "three",
    "tree",
    "two",
    "up",
    "visual",
    "wow",
    "yes",
    "zero",
  ]
max_samples: null
batch_size: 32
num_workers: 0
device: cuda
sample_rate: 16000
lr: 1e-3
model_name: tf_mobilenetv3_small_minimal_100
in_chans: 1
loss_function_name: BCEWithLogitsLoss
data_balance: False
checkpoint_path: null
seed: 0
early_stopping: True
patience: 3
default_root_dir: save/
gpus: 1
precision: 32
max_epochs: 100
web_interface: True
examples:
  [
    "examples/SPEECHCOMMANDS/32ad5b65_nohash_2.wav",
    "examples/SPEECHCOMMANDS/3a33d3a4_nohash_2.wav",
    "examples/SPEECHCOMMANDS/3ca784ec_nohash_0.wav",
    "examples/SPEECHCOMMANDS/ab5d7179_nohash_0.wav",
    "examples/SPEECHCOMMANDS/cae62f38_nohash_0.wav",
  ]
tuning_test: False
cpu_resources_per_trial: 1
gpu_resources_per_trial: 1
num_samples: 100

#  transforms configuration
transforms_config:
  train:
    selfdefined.DigitalFilter:
      filter_type: bandpass
      sample_rate: 16000
      cutoff_freq: [300, 3000]
    selfdefined.PadWaveform:
      max_waveform_length: 16000
    torchaudio.MelSpectrogram:
      sample_rate: 16000
      n_mels: 64
    torchaudio.AmplitudeToDB: null
    torchvision.Resize:
      - 64
      - 81
    torchvision.RandomErasing:
      value: -80

  val:
    selfdefined.DigitalFilter:
      filter_type: bandpass
      sample_rate: 16000
      cutoff_freq: [300, 3000]
    selfdefined.PadWaveform:
      max_waveform_length: 16000
    torchaudio.MelSpectrogram:
      sample_rate: 16000
      n_mels: 64
    torchaudio.AmplitudeToDB: null
    torchvision.Resize:
      - 64
      - 81

  test:
    selfdefined.DigitalFilter:
      filter_type: bandpass
      sample_rate: 16000
      cutoff_freq: [300, 3000]
    selfdefined.PadWaveform:
      max_waveform_length: 16000
    torchaudio.MelSpectrogram:
      sample_rate: 16000
      n_mels: 64
    torchaudio.AmplitudeToDB: null
    torchvision.Resize:
      - 64
      - 81

  predict:
    selfdefined.DigitalFilter:
      filter_type: bandpass
      sample_rate: 16000
      cutoff_freq: [300, 3000]
    selfdefined.PadWaveform:
      max_waveform_length: 16000
    torchaudio.MelSpectrogram:
      sample_rate: 16000
      n_mels: 64
    torchaudio.AmplitudeToDB: null
    torchvision.Resize:
      - 64
      - 81

#  target transforms configuration
target_transforms_config:
  train:
    selfdefined.LabelSmoothing:
      alpha: 0.2
      num_classes: null

  val:
    selfdefined.OneHotEncoder:
      num_classes: null

  test:
    selfdefined.OneHotEncoder:
      num_classes: null

  predict:
    selfdefined.OneHotEncoder:
      num_classes: null

#  optimizers configuration
optimizers_config:
  Adam:
    betas:
      - 0.9
      - 0.999
    eps: 1e-08
    weight_decay: 0
    amsgrad: False

#  learning rate schedulers configuration
lr_schedulers_config:
  CosineAnnealingLR:
    T_max: 10

#  hyperparameter space configuration
hyperparameter_space_config:
  lr:
    uniform:
      lower: 1e-4
      upper: 1e-1

  max_epochs:
    randint:
      lower: 10
      upper: 200
